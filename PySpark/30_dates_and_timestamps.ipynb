{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/18 23:38:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/02/18 23:38:38 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/02/18 23:38:38 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "23/02/18 23:38:38 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "23/02/18 23:38:38 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(name='dates_and_timestamps').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184 7\n",
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\n",
    "    path='data/aapl.csv',\n",
    "    inferSchema=True,\n",
    "    header=True\n",
    ")\n",
    "print(df.count(), len(df.columns))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Date=datetime.datetime(2014, 9, 29, 0, 0), Open=100.589996, High=100.690002, Low=98.040001, Close=99.620003, Adj Close=93.51429, Volume=142718700),\n",
       " Row(Date=datetime.datetime(2014, 10, 6, 0, 0), Open=99.949997, High=102.379997, Low=98.309998, Close=100.730003, Adj Close=94.556244, Volume=280258200),\n",
       " Row(Date=datetime.datetime(2014, 10, 13, 0, 0), Open=101.330002, High=101.779999, Low=95.18, Close=97.669998, Adj Close=91.683792, Volume=358539800),\n",
       " Row(Date=datetime.datetime(2014, 10, 20, 0, 0), Open=98.32, High=105.489998, Low=98.220001, Close=105.220001, Adj Close=98.771042, Volume=358532900),\n",
       " Row(Date=datetime.datetime(2014, 10, 27, 0, 0), Open=104.849998, High=108.040001, Low=104.699997, Close=108.0, Adj Close=101.380676, Volume=220230600)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+----------+----------+----------+----------+---------+\n",
      "|               Date|      Open|      High|       Low|     Close| Adj Close|   Volume|\n",
      "+-------------------+----------+----------+----------+----------+----------+---------+\n",
      "|2014-09-29 00:00:00|100.589996|100.690002| 98.040001| 99.620003|  93.51429|142718700|\n",
      "|2014-10-06 00:00:00| 99.949997|102.379997| 98.309998|100.730003| 94.556244|280258200|\n",
      "|2014-10-13 00:00:00|101.330002|101.779999|     95.18| 97.669998| 91.683792|358539800|\n",
      "|2014-10-20 00:00:00|     98.32|105.489998| 98.220001|105.220001| 98.771042|358532900|\n",
      "|2014-10-27 00:00:00|104.849998|108.040001|104.699997|     108.0|101.380676|220230600|\n",
      "+-------------------+----------+----------+----------+----------+----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function pyspark.sql.functions.years(col: 'ColumnOrName') -> pyspark.sql.column.Column>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F.dayofmonth\n",
    "# F.hour\n",
    "# F.dayofyear\n",
    "# F.month\n",
    "# F.year\n",
    "# F.weekofyear\n",
    "# F.format_number\n",
    "# F.date_formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|dayofmonth(Date)|\n",
      "+----------------+\n",
      "|              29|\n",
      "|               6|\n",
      "|              13|\n",
      "|              20|\n",
      "|              27|\n",
      "+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(F.dayofmonth(df['Date'])).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|month(Date)|\n",
      "+-----------+\n",
      "|         12|\n",
      "|          1|\n",
      "|          6|\n",
      "|          3|\n",
      "|          5|\n",
      "|          9|\n",
      "|          4|\n",
      "|          8|\n",
      "|          7|\n",
      "|         10|\n",
      "|         11|\n",
      "|          2|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(F.month(df['Date'])).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "670cec61e4f3692aefc152a66589482a97497120e6ec7ba5bd571042f4733341"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
